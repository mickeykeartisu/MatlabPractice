<?xml version="1.0" encoding="EUC-JP"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
   "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<!-- XML file produced from file: morphingWithSTRAIGHT.tex
     using Hyperlatex v 2.8 (c) Otfried Cheong
     on Emacs 21.2.1, Wed Oct 19 03:02:05 2005 -->
<head>
<title>Morphing with STRAIGHT -- 時間長の制御</title>

<style type="text/css">
.maketitle { align : center }
div.abstract { margin-left: 20%; margin-right: 10%; }
h3.abstract  { align : center }
div.verse, div.quote, div.quotation {
  margin-left : 10%; 
  margin-right : 10%;
}
dt {font-weight: bold}
</style>
</head>
<body bgcolor="#ffffe6">
<table width="100%" cellpadding="0" cellspacing="2"><tr>
<td bgcolor="#99ccff"><a href="morphingWithSTRAIGHT_25.html"><img border="0" alt="母音部フォルマントの変換" src="next.png"/></a></td><td bgcolor="#99ccff"><a href="morphingWithSTRAIGHT_23.html"><img border="0" alt="モーフィングの応用" src="up.png"/></a></td><td bgcolor="#99ccff"><img alt="" src="blank.png"/></td><td align="center" bgcolor="#99ccff" width="100%"><b>時間長の制御</b></td><td bgcolor="#99ccff" align="center"><a href="morphingWithSTRAIGHT_28.html">Contents</a></td><td bgcolor="#99ccff" align="center"><a href="morphingWithSTRAIGHT_27.html">Index</a></td></tr></table>
<h2>時間長の制御</h2>
<p>ここでは，男性の発声した「あいうえお」という母音連鎖を例にとって説明します。
前と同様に，モーフィングオブジェクトを作成します。
</p><pre>
[x,fs]=wavread('../STRAIGHTV40_003b/vaiueo2d.wav');
aiueoObj = createMobject
aiueoObj = updateFieldOfMobject(aiueoObj,'waveform',x);
aiueoObj = updateFieldOfMobject(aiueoObj,'samplingFrequency',fs);
</pre>
<p>ここで，STRAIGHT分析を行い，スペクトログラムを表示します。
</p><pre>
aiueoObj = executeSTRAIGHTanalysisM(aiueoObj);
displayMobject(aiueoObj,'anchorFrequency','aiueoObj');
axis([0 794 0 5000])
</pre>
<div class="quote"><p>
<img src="sgramaiueoObjPlain.png"  /></p></div>
<p>今回の例では、それぞれの母音の時間長を操作するので，まず，
それぞれの母音の区間を決める必要があります。
厳密な議論をすると，どこからどこまでがどの母音に対応しているかという
設問はナンセンスなものだということになります。
しかし，ここでは，厳密な議論は避けて，便宜的にそれぞれの母音の間に境界があると考え，
境界と境界の間を，それぞれの母音の区間であると考えることにします。
スペクトログラムから視察でそのような境界を求めると，
116,   240,   400,   500,   610,   710 msの位置に設定するのが妥当に見えます。
今回は，時刻だけが重要なので、特徴点の周波数を仮に 1000Hzとして，以下のように
特徴点情報を作成します。
</p><pre>
rawanch =[116 -10;240 1000;400 1000;500 1000;610 1000;710 -10];
</pre>
<p>116msと710msは，音声の開始と終了の位置です。
そのような性質の境界であることを示すため、それらの時刻には負の周波数を入れてあります。
この情報を用いて，先ほど作成したモーフィングオブジェクトの特徴点情報を設定します。
スペクトログラムと特徴点を表示して確認しておきます。
</p><pre>
aiueoObj = setAnchorFromRawAnchor(aiueoObj,rawanch)
displayMobject(aiueoObj,'anchorFrequency','aiueoObj');
axis([0 794 0 5000])
</pre>
<div class="quote"><p>
<img src="sgramaiueoObj.png"  /></p></div>
<p>母音区間の長さは、特徴点の時刻の差分として求めることができます。
</p><pre>
&gt;&gt; diff(aiueoObj.anchorTimeLocation)'

ans =

   124   160   100   110   100
</pre>
<p>ここで，2番目の区間「い」に対応する部分と
4番目の区間「え」に対応する部分の時間長を3倍にすることにします。
そのために，まず，目標とする時刻を持つオブジェクトを作成する必要があります。
以下の操作が，それらに対応します。
</p><pre>
modaiueoObj = aiueoObj;
modaiueoObj.anchorTimeLocation = cumsum([116;124 ;  160*3  ; 100 ;  110*3;   100]);
</pre>
<p>また，時間長が増加したことに対応して，目標とするオブジェクトのそれぞれの
属性に対応するデータのサイズを調整しておく必要があります。
ここでは，そのための関数<tt>fixDummyObjectSize</tt>を用います。
</p><pre>
modaiueoObj = fixDummyObjectSize(modaiueoObj,aiueoObj);
</pre>
次に，モーフィング率を制御する構造体を作成します。
<p>ここでは，時間周波数変換のみを行いますので，以下のように設定します。
</p><pre>
mRate.F0 =0;
mRate.aperiodicity=0;
mRate.spectrum=0;
mRate.coordinate=1;
</pre>
モーフィングは，以下の命令で実行します。
<p>ここでも，モーフィング結果を表示して確認しておきます。
</p><pre>
mixAIUf0s0a0c1 = timeFrequencySTRAIGHTmorphing(aiueoObj,modaiueoObj,mRate,'log');
displayMobject(mixAIUf0s0a0c1,'anchorFrequency','mixAIUf0s0a0c1');
axis([0 1334 0 5000])
</pre>
<div class="quote"><p>
<img src="sgrammixAIUf0s0a0c1.png"  /></p></div>
スペクトログラムを見ると，確かに「い」と「え」に相当する部分が時間方向に
<p>引き延ばされていることが分かります。
以下の命令により，この変換されたモーフィングオブジェクトから音声を合成します。
</p><pre>
syAIUmixf0s0a0c1 = executeSTRAIGHTsynthesisM(mixAIUf0s0a0c1);
</pre>
<p>以下に，元の音声と変換された音声をリンクしておきます。
3倍という極端な変換を行ったはずですが，
「え」の区間はそれほど大きな変換が加わったようには聴こえません。
逆に「い」の区間は，3倍以上に伸びているように感じられます。
知覚は物理的実体そのものではないことを示す一例です。
</p><ul><li><a href="vaiueo2d.wav">原音声（vaiueo2d.wav）</a>
</li><li><a href="syAIUmixf0s0a0c1.wav">時間軸を変換された音声（syAIUmixf0s0a0c1.wav）</a>
</li></ul>
<hr /><address>Hideki Kawahara, October 19, 2005</address><br />
<table width="100%" cellpadding="0" cellspacing="2"><tr>
<td bgcolor="#99ccff"><a href="morphingWithSTRAIGHT_25.html"><img border="0" alt="母音部フォルマントの変換" src="next.png"/></a></td><td bgcolor="#99ccff"><a href="morphingWithSTRAIGHT_23.html"><img border="0" alt="モーフィングの応用" src="up.png"/></a></td><td bgcolor="#99ccff"><img alt="" src="blank.png"/></td><td align="center" bgcolor="#99ccff" width="100%"><b>時間長の制御</b></td><td bgcolor="#99ccff" align="center"><a href="morphingWithSTRAIGHT_28.html">Contents</a></td><td bgcolor="#99ccff" align="center"><a href="morphingWithSTRAIGHT_27.html">Index</a></td></tr></table></body></html>
